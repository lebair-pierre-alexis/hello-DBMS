# hello-DBMS
This project is part of Laplateforme curiculum, the goal of this project is to train our ability to manage databases and make efficient requests.
This readme will contain the research and base notions regarding SQL. It will also be split in two with the english version of the readme and the french version.

### Question 1 : What is a data and what form can it take ?

A data is a piece of information, it can takes countless forms such as a number representing the age of someone, text, a voice recording, a video, electric signals and so on ...
Data are the base on which AI is built, without data to analyze and process there is no AI. Those pieces of informations, within the right context can give very meaningfull insights.

### Question 2 : List and explain the different mesurement criteria regarding data

**Data Quality Measurement Criteria and Explanations:**

1. **Accuracy:**
   - *Definition:* Accuracy measures the proximity between data and reality.
   - *Explanation:* Data should accurately reflect the characteristics and values they represent. Errors can occur during data collection, entry, or processing.

2. **Completeness:**
   - *Definition:* Completeness evaluates the presence of all necessary and expected data.
   - *Explanation:* Data must be complete, without crucial information gaps. Data gaps can lead to biased or incomplete analyses.

3. **Consistency:**
   - *Definition:* Consistency examines the harmonization of data across different sources.
   - *Explanation:* Data should be consistent across different databases and systems. Inconsistencies can lead to errors and contradictions.

4. **Timeliness:**
   - *Definition:* Timeliness measures the temporal relevance of data.
   - *Explanation:* Data should be updated in a timely manner to reflect changes in reality. Outdated data can lead to obsolete analyses.

5. **Precision:**
   - *Definition:* Precision concerns the level of detail or granularity of data.
   - *Explanation:* Data should be sufficiently precise to meet specific analysis needs. Overly aggregated data can mask important trends.

6. **Validity:**
   - *Definition:* Validity evaluates whether data conforms to predefined rules and standards.
   - *Explanation:* Data must adhere to established constraints and rules, avoiding outliers or formatting errors.

7. **Uniformity:**
   - *Definition:* Uniformity examines the standardization of data across different sources.
   - *Explanation:* Data should follow common standards and formats to ensure easy interoperability and eliminate unnecessary divergences.

8. **Integrity:**
   - *Definition:* Integrity measures the reliability and stability of data over time.
   - *Explanation:* Data should remain consistent and reliable even during updates or modifications. Integrity ensures the longevity of information.

The evaluation of data quality often involves a combination of these criteria to ensure reliable and actionable data. Organizations implement data quality management processes to monitor and continuously improve the quality of their data.